
<!DOCTYPE html>

<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SVM linéaire &#8212; Apprentissage automatique</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="next" title="Astuce du noyau" href="kernelTrick.html" />
    <link rel="prev" title="Arbres de décision" href="arbres_decision.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="fr">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Apprentissage automatique</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Apprentissage automatique
                </a>
            </li>
        </ul>
        <p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="possible.html">
   Exemple introductif
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="approchestat.html">
   Modèle statistique de l’apprentissage
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="modelesup.html">
   Modèle du processus d’apprentissage supervisé
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bayes.html">
   Classifieur naïf de Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="LDAQDA.html">
   Analyses discriminantes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="knn.html">
   K plus proches voisins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="arbres_decision.html">
   Arbres de décision
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Méthodes à noyau
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   SVM linéaire
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kernelTrick.html">
   Astuce du noyau
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Méthodes d'ensemble
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="baggingboosting.html">
   Bootstraping et bagging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="adaboost.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="combinaison.html">
   Méthodes de combinaison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="randomforest.html">
   Forêts aléatoires
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gradientboosting.html">
   Gradient Boosting
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Manifold learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="mds.html">
   Positionnement multidimensionnel
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="isomap.html">
   ISOMAP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lle.html">
   Local Linear Embedding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="manifold.html">
   Unification
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/vbarra/anbook.git"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/vbarra/anbook.git/issues/new?title=Issue%20on%20page%20%2FsvmGeom.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/svmGeom.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="_sources/svmGeom.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   SVM linéaire
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperplan-separateur">
     Hyperplan séparateur
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probleme-d-optimisation">
     Problème d’optimisation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#donnees-non-lineairement-separables">
     Données non linéairement séparables
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cas-multiclasses">
     Cas multiclasses
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-non-lineaire">
   SVM non linéaire
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilisation-en-regression">
   Utilisation en régression
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>SVM linéaire</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   SVM linéaire
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperplan-separateur">
     Hyperplan séparateur
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probleme-d-optimisation">
     Problème d’optimisation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#donnees-non-lineairement-separables">
     Données non linéairement séparables
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cas-multiclasses">
     Cas multiclasses
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-non-lineaire">
   SVM non linéaire
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilisation-en-regression">
   Utilisation en régression
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p>Soit <span class="math notranslate nohighlight">\(Z = \{ \mathbf x_i , y_i\}, \; i\in[\![1,n]\!] ,\;\mathbf x_i \in {R}^d, y_i \in \{-1,1\}\}\)</span> un ensemble d’apprentissage pour un problème de classification binaire.</p>
<div class="tex2jax_ignore mathjax_ignore section" id="svm-lineaire">
<h1>SVM linéaire<a class="headerlink" href="#svm-lineaire" title="Lien permanent vers ce titre">#</a></h1>
<div class="section" id="hyperplan-separateur">
<h2>Hyperplan séparateur<a class="headerlink" href="#hyperplan-separateur" title="Lien permanent vers ce titre">#</a></h2>
<p>Une approche traditionnelle pour introduire les SVM est de partir du concept d’hyperplan séparateur des exemples positifs et négatifs de l’ensemble d’apprentissage. On définit alors la marge comme la distance du plus proche exemple à cet hyperplan, et on espère intuitivement que plus grande sera cette marge, meilleure sera la capacité de généralisation de ce séparateur linéaire.</p>
<p>Un hyperplan de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> est défini par</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T\mathbf x + b = 0\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf w\)</span> étant le vecteur normal à l’hyperplan. La fonction</p>
<div class="math notranslate nohighlight">
\[\label{eq:f} 
f({\mathbf x}) = \textrm{sign}( {\mathbf w^T\mathbf x} + b )
\]</div>
<p>permet, si elle sépare les données d’apprentissage, de les classifier correctement (<a class="reference internal" href="#hyp-ref"><span class="std std-numref">Fig. 11</span></a>).</p>
<div class="figure align-default" id="hyp-ref">
<img alt="_images/hyperplan.png" src="_images/hyperplan.png" />
<p class="caption"><span class="caption-number">Fig. 11 </span><span class="caption-text">Hyperplan séparateur et définition de <span class="math notranslate nohighlight">\(\mathbb w\)</span></span><a class="headerlink" href="#hyp-ref" title="Lien permanent vers cette image">#</a></p>
</div>
<p>Un tel hyperplan, représenté par (<span class="math notranslate nohighlight">\(\mathbf w,b)\)</span> peut également être exprimé par <span class="math notranslate nohighlight">\((\lambda \mathbf w,\lambda b), \lambda\in\mathbb{R}\)</span>. Il est donc nécessaire de définir l’hyperplan canonique comme étant celui éloigné des données d’une distance au moins égale à 1. En fait, on impose qu’un exemple au moins de chaque classe soit à distance égale à 1. On considère alors le couple <span class="math notranslate nohighlight">\((\mathbf w,b)\)</span> tel que :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf w^T\mathbf x_i + b \ge +1 \ \ \textrm{si} \ \ y_i = +1 \\
\mathbf w^T\mathbf x_i + b \le -1 \ \ \textrm{si} \ \ y_i = -1
\end{split}\]</div>
<p>ou de manière plus compacte</p>
<div class="math notranslate nohighlight">
\[\forall i\quad y_i (\mathbf  w^T\mathbf x_i + b) \ge 1\]</div>
<p>les hyperplans <span class="math notranslate nohighlight">\(mathbf w^T\mathbf x_i + b =\pm 1\)</span> sont appelés les hyperplans supports.</p>
<p>Une infinité d’hyperplans sépare deux nuages de points linéairement séparables (<a class="reference internal" href="#infhyp-ref"><span class="std std-numref">Fig. 12</span></a>)</p>
<div class="figure align-default" id="infhyp-ref">
<img alt="_images/hyperplanmarge.png" src="_images/hyperplanmarge.png" />
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">Hyperplans séparateurs</span><a class="headerlink" href="#infhyp-ref" title="Lien permanent vers cette image">#</a></p>
</div>
<p>On cherche à avoir la marge la plus grande possible, et on suppose qu’au moins un point de donnée appartient aux hyperplans support. Il existe donc <span class="math notranslate nohighlight">\(\mathbf x_1,\mathbf x_2\)</span> tels que <span class="math notranslate nohighlight">\(\mathbf w^T\mathbf x_1 + b =1\)</span> et <span class="math notranslate nohighlight">\(\mathbf w^T\mathbf x_2 + b =-1\)</span>. On en déduit</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T(\mathbf x_1-\mathbf x_2) =2\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf w\)</span> étant orthogonal aux hyperplans, la marge est la projection orthogonale de <span class="math notranslate nohighlight">\(\mathbf x_1-\mathbf x_2\)</span> sur <span class="math notranslate nohighlight">\(\mathbf w\)</span>. Cette projection est définie par la matrice <span class="math notranslate nohighlight">\(P=\frac{\mathbf w\mathbf w^T}{\mathbf w^T\mathbf w}\)</span> et donc le vecteur projection de <span class="math notranslate nohighlight">\(\mathbf x_1-\mathbf x_2\)</span> sur la droite engendrée par <span class="math notranslate nohighlight">\(\mathbf w\)</span> est</p>
<div class="math notranslate nohighlight">
\[\frac{\mathbf w^T(x_1-\mathbf x_2)}{\mathbf w^T\mathbf w}\mathbf w = \frac{2}{\|\mathbf w\|}\]</div>
<p>L’équation précédente permet d’affirmer que maximiser la marge revient à minimiser <span class="math notranslate nohighlight">\(\|\mathbf w\|\)</span>, sous les contraintes de bonne classification (<a class="reference internal" href="#hyp2-ref"><span class="std std-numref">Fig. 13</span></a>).</p>
<div class="figure align-default" id="hyp2-ref">
<img alt="_images/hyperplanmarge2.png" src="_images/hyperplanmarge2.png" />
<p class="caption"><span class="caption-number">Fig. 13 </span><span class="caption-text">Maximisation de la marge</span><a class="headerlink" href="#hyp2-ref" title="Lien permanent vers cette image">#</a></p>
</div>
</div>
<div class="section" id="probleme-d-optimisation">
<h2>Problème d’optimisation<a class="headerlink" href="#probleme-d-optimisation" title="Lien permanent vers ce titre">#</a></h2>
<p>Le problème s’écrit alors comme un problème de minimisation sous contraintes :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\min_{\mathbf w\in\mathbb{R}^d} \|\mathbf w \|^2\\
\textrm{sous }y_i(\mathbf  w^T\mathbf  x_i) \geq 1,\quad i\in[\![1,n]\!]\\
\end{split}\]</div>
<p>En introduisant les multiplicateurs de Lagrange, le problème dual s’écrit :</p>
<div class="math notranslate nohighlight">
\[
min  \ W(\boldsymbol\alpha) = -\displaystyle\sum_{i=1}^n{\alpha_i} +
\frac{1}{2} \displaystyle\sum_{i=1}^{n}\displaystyle \sum_{j=1}^ny_iy_j\alpha_i\alpha_j(\mathbf x_i ^T \mathbf x_j)  \]</div>
<p>sous</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sum_{i=1}^n y_i\alpha_i = 0 \]</div>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\; 0 \le \alpha_i \le C\]</div>
<p>où <span class="math notranslate nohighlight">\(\boldsymbol {\alpha}\)</span> est le vecteur des <span class="math notranslate nohighlight">\(n\)</span> multiplicateurs de Lagrange à déterminer, et <span class="math notranslate nohighlight">\(C\)</span> est une constante. En définissant la matrice <span class="math notranslate nohighlight">\((H)_{ij} = y_iy_j(\mathbf x_i ^T \mathbf x_j)\)</span> et <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> le vecteur de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> dont toutes les composantes sont égales à 1, le problème se réécrit comme un problème de programmation quadratique (QP) :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
min \label{eq:qp1}  W(\boldsymbol\alpha) = {-\boldsymbol\alpha}^T \mathbf{1} + \frac{1}{2}\boldsymbol\alpha^T H \boldsymbol\alpha
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp; \\
\textrm{sous } \label{eq:qp2}  \boldsymbol\alpha^T\boldsymbol y = 0
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp; \\
\label{eq:qp3}  {0} \le {\boldsymbol\alpha} \le C\mathbf{1}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp;
\end{split}\]</div>
<p>pour lequel de nombreuses méthodes de résolution ont été développées.</p>
<p>En dérivant l’équation précédente, il est possible de montrer que l’hyperplan optimal (canonique) peut être écrit comme</p>
<div class="math notranslate nohighlight">
\[\label{eq:w} \mathbf w = \displaystyle\sum_{i=1}^n \alpha_i y_i \mathbf x_i
\]</div>
<p>et <span class="math notranslate nohighlight">\(\mathbf w\)</span> est donc juste une combinaison linéaire des exemples d’apprentissage.</p>
<p>On peut également montrer que</p>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\quad \alpha_i(y_i(\mathbf w^T \mathbf x_i + b) - 1) = 0 
\]</div>
<p>ce qui exprime que lorsque <span class="math notranslate nohighlight">\(y_i(\mathbf w ^T \mathbf x_i + b) &gt; 1\)</span>, alors  <span class="math notranslate nohighlight">\(\alpha_i = 0\)</span> : seuls les points d’apprentissage les plus proches de l’hyperplan (tels que <span class="math notranslate nohighlight">\(\alpha_i &gt; 0\)</span>)  contribuent au calcul de ce dernier, et on les appelle les vecteurs de support.</p>
<p>En supposant avoir résolu le problème QP, et donc en disposant du <span class="math notranslate nohighlight">\(\boldsymbol {\alpha}\)</span> qui permet de calculer le vecteur <span class="math notranslate nohighlight">\(\mathbf w\)</span> optimal, il reste à déterminer le biais <span class="math notranslate nohighlight">\(b\)</span>. Pour cela, en prenant un exemple positif  <span class="math notranslate nohighlight">\(\mathbf x^+\)</span> et un exemple négatif  <span class="math notranslate nohighlight">\(\mathbf x^-\)</span> quelconques, pour lesquels</p>
<div class="math notranslate nohighlight">
\[\begin{split}(\mathbf w ^T \mathbf x^+ + b) = +1 \\
(\mathbf w ^T \mathbf x^- + b) = -1
\end{split}\]</div>
<p>on a</p>
<div class="math notranslate nohighlight">
\[b = - \frac{1}{2} ( \mathbf w ^T \mathbf x^+ + \mathbf w ^T \mathbf x^- )
\]</div>
<p>L’hyperplan ainsi défini a besoin de très peu de vecteurs de support (méthode éparse) (<a class="reference internal" href="#svmlin-ref"><span class="std std-numref">Fig. 14</span></a>).</p>
<div class="cell tag_margin tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=...</span>
<span class="n">svm_clf</span><span class="o">=</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="svmlin-ref">
<img alt="_images/svmLin.png" src="_images/svmLin.png" />
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">Les vecteurs de support sont entourés.</span><a class="headerlink" href="#svmlin-ref" title="Lien permanent vers cette image">#</a></p>
</div>
</div>
<div class="section" id="donnees-non-lineairement-separables">
<h2>Données non linéairement séparables<a class="headerlink" href="#donnees-non-lineairement-separables" title="Lien permanent vers ce titre">#</a></h2>
<p>Il reste à préciser le rôle de la contrainte <span class="math notranslate nohighlight">\({0} \le {\boldsymbol \alpha} \le C\mathbf{1}\)</span>.
Lorsque <span class="math notranslate nohighlight">\(C\rightarrow\infty\)</span>, l’hyperplan optimal est celui qui sépare totalement les données d’apprentissage (si tant est qu’il existe). Pour des valeurs de <span class="math notranslate nohighlight">\(C\)</span> « raisonnables », des erreurs de classification peuvent être acceptées par le classifieur (soft margin). Pour cela on introduit des variables d’écart <span class="math notranslate nohighlight">\(\xi_i\)</span> :</p>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\quad y_i(\mathbf w ^T \mathbf x_i + b) &gt; 1-\xi_i\]</div>
<p>Les vecteurs de support vérifient l’égalité, et les anciennes contraintes peuvent être violées de deux manières :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((\mathbf x_i,y_i)\)</span> est à distance inférieure à la marge, mais du bon côté de l’hyperplan</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf x_i,y_i)\)</span> est du mauvais côté de l’hyperplan</p></li>
</ul>
<p>L’objectif est alors de minimiser  la moyenne des erreurs de classification <span class="math notranslate nohighlight">\(\displaystyle\sum_{i=1}^n \mathbf{1}_{\xi_i&gt;0}\)</span>. Ce problème étant NP-complet (fonction non continue et dérivable), on lui préfère le problème suivant</p>
<div class="math notranslate nohighlight">
\[\begin{split}	Min \frac{1}{2}\mathbf w^T\mathbf w + C\displaystyle\sum_{i}^n \xi_i\\
	sous\;  y_i\left ( \mathbf w^T\mathbf x_i+b\right )= 1-\xi_i
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(C\)</span> représente alors un compromis entre la marge possible entre les exemples et le nombre d’erreurs admissibles.
Nous illustrons dans la suite deux situations influencées par <span class="math notranslate nohighlight">\(C\)</span> :</p>
<ul class="simple">
<li><p>La <a class="reference internal" href="#soft1-ref"><span class="std std-numref">Fig. 15</span></a> présente une première illustration du rôle de <span class="math notranslate nohighlight">\(C\)</span> : dans le cas de données linéairement séparables, un <span class="math notranslate nohighlight">\(C\)</span> faible autorisera des  vecteurs à rentrer dans la marge (vert). Plus <span class="math notranslate nohighlight">\(C\)</span> devient grand, plus le nombre de vecteurs support diminue, pour ne laisser aucun vecteur à distance inférieure à la marge de l’hyperplan optimal</p></li>
</ul>
<div class="figure align-default" id="soft1-ref">
<img alt="_images/soft1.png" src="_images/soft1.png" />
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Données linéairement séparables</span><a class="headerlink" href="#soft1-ref" title="Lien permanent vers cette image">#</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Video</span>
<span class="n">Video</span><span class="p">(</span><span class="s2">&quot;videos/influencec.mp4&quot;</span><span class="p">,</span><span class="n">embed</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_margin tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=...</span>
<span class="n">svm_clf</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1E10</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La <a class="reference internal" href="#soft2-ref"><span class="std std-numref">Fig. 16</span></a> présente un ensemble de données non linéairement séparables. La valeur de <span class="math notranslate nohighlight">\(C\)</span> contrôle le nombre d’erreurs de classification dans le résultat final.</p></li>
</ul>
<div class="figure align-default" id="soft2-ref">
<img alt="_images/soft2.png" src="_images/soft2.png" />
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">Données non linéairement séparables</span><a class="headerlink" href="#soft2-ref" title="Lien permanent vers cette image">#</a></p>
</div>
</div>
<div class="section" id="cas-multiclasses">
<h2>Cas multiclasses<a class="headerlink" href="#cas-multiclasses" title="Lien permanent vers ce titre">#</a></h2>
<p>Deux stratégies sont possibles dans le cas multiclasse :</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="38464d56-4331-4492-aed0-43e2346226b1" name="02d81814-4c13-4b2e-937d-6f683bb4257b" type="radio">
</input><label class="sd-tab-label" for="38464d56-4331-4492-aed0-43e2346226b1">
Un contre tous</label><div class="sd-tab-content docutils">
<p>Transformer le problème à <span class="math notranslate nohighlight">\(k\)</span> classes en <span class="math notranslate nohighlight">\(k\)</span> classifieurs binaires, la classe de l’exemple est donnée par le classifieur qui répond le mieux
<img alt="" src="_images/ova1.png" /></p>
</div>
<input id="cf3fd67f-0ee1-4790-9846-ff532bb05690" name="02d81814-4c13-4b2e-937d-6f683bb4257b" type="radio">
</input><label class="sd-tab-label" for="cf3fd67f-0ee1-4790-9846-ff532bb05690">
Un contre un</label><div class="sd-tab-content docutils">
<p>Transformer le problème en <span class="math notranslate nohighlight">\(\frac{k(k-1)}{2}\)</span> classifieurs binaires, chaque classe étant comparée aux autres. La classe de l’exemple est donnée par le vote majoritaire ou par un graphe acyclique de décision
<img alt="" src="_images/ova2.png" /></p>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="svm-non-lineaire">
<h1>SVM non linéaire<a class="headerlink" href="#svm-non-lineaire" title="Lien permanent vers ce titre">#</a></h1>
<p>Pour utiliser les SVM dans un contexte non linéaire, on profite de l”<a class="reference internal" href="kernelTrick.html"><span class="doc std std-doc">astuce du noyau</span></a> puisque le modèle s’écrit avec un produit scalaire canonique.</p>
<div class="margin sidebar">
<p class="sidebar-title">Exemple de regression</p>
<p><img alt="" src="_images/ridgeregression.png" /></p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="utilisation-en-regression">
<h1>Utilisation en régression<a class="headerlink" href="#utilisation-en-regression" title="Lien permanent vers ce titre">#</a></h1>
<p>Il est également possible, en changeant les fonctions de perte,  d’utiliser les SVM  en régression non paramétrique (SVR : Support Vector Regression)
, i.e. approcher une fonction de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> dans <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span> par les mêmes mécanismes d’optimisation.</p>
<p>Pour illustrer les SVR, on génère des données aléatoires 2D à tendance linéaire et on utilise LinearSVR pour effectuer une régression linéaire.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$y$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="s2">&quot;bo&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Un SVR linéaire est principalement défini par un paramètre <span class="math notranslate nohighlight">\(\epsilon\)</span>, qui spécifie la largeur du tube dans lequel aucune pénalité n’est associée.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>
<span class="n">svm_reg1</span> <span class="o">=</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_reg2</span> <span class="o">=</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_reg1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">svm_reg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">off_margin</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">off_margin</span><span class="p">)</span>

<span class="n">svm_reg1</span><span class="o">.</span><span class="n">support_</span> <span class="o">=</span> <span class="n">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">svm_reg2</span><span class="o">.</span><span class="n">support_</span> <span class="o">=</span> <span class="n">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg2</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">eps_x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">eps_y_pred</span> <span class="o">=</span> <span class="n">svm_reg1</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">eps_x1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>On affiche alors les régresseurs linéaires</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">x1s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x1s</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="s2">&quot;c-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\hat</span><span class="si">{y}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">svm_reg</span><span class="o">.</span><span class="n">support_</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">svm_reg</span><span class="o">.</span><span class="n">support_</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;#FFAAAA&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$y$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg1</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\epsilon = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svm_reg1</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">eps_x1</span><span class="p">,</span> <span class="n">eps_y_pred</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">eps_x1</span><span class="p">,</span> <span class="n">eps_y_pred</span> <span class="o">-</span> <span class="n">svm_reg1</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">arrowprops</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;arrowstyle&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;-&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;linewidth&#39;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">}</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.91</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\epsilon$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg2</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\epsilon = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svm_reg2</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Video</span>
<span class="n">Video</span><span class="p">(</span><span class="s2">&quot;videos/svr_regression_lin.mp4&quot;</span><span class="p">,</span><span class="n">embed</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p id="id1"><dl class="citation">
<dt class="label" id="id61"><span class="brackets">Cov65</span></dt>
<dd><p>Thomas M. Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. <em>Electronic Computers, IEEE Transactions on</em>, EC-14(3):326–334, 1965. URL: <a class="reference external" href="http://hebb.mit.edu/courses/9.641/2002/readings/Cover65.pdf">http://hebb.mit.edu/courses/9.641/2002/readings/Cover65.pdf</a>.</p>
</dd>
<dt class="label" id="id51"><span class="brackets">VC71</span></dt>
<dd><p>V. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. <em>Theory of Probability and its Applications</em>, 16(2):264–280, 1971.</p>
</dd>
<dt class="label" id="id50"><span class="brackets">Vap91</span></dt>
<dd><p>Vladimir Vapnik. Principles of risk minimization for learning theory. In <em>NIPS</em>, 831–838. Morgan Kaufmann, 1991.</p>
</dd>
</dl>
</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "vbarra/anbook.git",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="arbres_decision.html" title="précédent page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">précédent</p>
            <p class="prev-next-title">Arbres de décision</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="kernelTrick.html" title="suivant page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Astuce du noyau</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Vincent BARRA<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>