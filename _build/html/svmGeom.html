
<!DOCTYPE html>


<html lang="fr" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>SVM linéaire &#8212; Apprentissage automatique</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=72dce1d2"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="_static/translations.js?v=bf059b8c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'svmGeom';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="next" title="Astuce du noyau" href="kernelTrick.html" />
    <link rel="prev" title="Ressources" href="docKernels.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Passer au contenu principal</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Haut de page
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Apprentissage automatique - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Apprentissage automatique - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="docIntro.html">Ressources</a></li>
<li class="toctree-l1"><a class="reference internal" href="possible.html">Exemple introductif</a></li>

<li class="toctree-l1"><a class="reference internal" href="approchestat.html">Modèle statistique de l’apprentissage</a></li>

<li class="toctree-l1"><a class="reference internal" href="modelesup.html">Modèle du processus d’apprentissage supervisé</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="docClassif.html">Ressources</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">Classifieur naïf de Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="LDAQDA.html">Analyses discriminantes</a></li>
<li class="toctree-l1"><a class="reference internal" href="knn.html">K plus proches voisins</a></li>
<li class="toctree-l1"><a class="reference internal" href="arbres_decision.html">Arbres de décision</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Méthodes à noyau</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="docKernels.html">Ressources</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">SVM linéaire</a></li>


<li class="toctree-l1"><a class="reference internal" href="kernelTrick.html">Astuce du noyau</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Méthodes d'ensemble</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="docEnsemble.html">Ressources</a></li>
<li class="toctree-l1"><a class="reference internal" href="baggingboosting.html">Bootstraping et bagging</a></li>
<li class="toctree-l1"><a class="reference internal" href="adaboost.html">Boosting</a></li>

<li class="toctree-l1"><a class="reference internal" href="combinaison.html">Méthodes de combinaison</a></li>
<li class="toctree-l1"><a class="reference internal" href="randomforest.html">Forêts aléatoires</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradientboosting.html">Gradient Boosting</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Manifold learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mds.html">Positionnement multidimensionnel</a></li>



<li class="toctree-l1"><a class="reference internal" href="isomap.html">ISOMAP</a></li>



<li class="toctree-l1"><a class="reference internal" href="lle.html">Local Linear Embedding</a></li>


<li class="toctree-l1"><a class="reference internal" href="manifold.html">Unification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="TPClassif.html">Comparaison de méthodes de classification supervisée</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Mode plein écran"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>SVM linéaire</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenu </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">SVM linéaire</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperplan-separateur">Hyperplan séparateur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probleme-d-optimisation">Problème d’optimisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#donnees-non-lineairement-separables">Données non linéairement séparables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cas-multiclasses">Cas multiclasses</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-non-lineaire">SVM non linéaire</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#utilisation-en-regression">Utilisation en régression</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>Soit <span class="math notranslate nohighlight">\(Z = \{ \mathbf x_i , y_i\}, \; i\in[\![1,n]\!] ,\;\mathbf x_i \in {R}^d, y_i \in \{-1,1\}\}\)</span> un ensemble d’apprentissage pour un problème de classification binaire.</p>
<section class="tex2jax_ignore mathjax_ignore" id="svm-lineaire">
<h1>SVM linéaire<a class="headerlink" href="#svm-lineaire" title="Lien vers cette rubrique">#</a></h1>
<section id="hyperplan-separateur">
<h2>Hyperplan séparateur<a class="headerlink" href="#hyperplan-separateur" title="Lien vers cette rubrique">#</a></h2>
<p>Une approche traditionnelle pour introduire les SVM est de partir du concept d’hyperplan séparateur des exemples positifs et négatifs de l’ensemble d’apprentissage. On définit alors la marge comme la distance du plus proche exemple à cet hyperplan, et on espère intuitivement que plus grande sera cette marge, meilleure sera la capacité de généralisation de ce séparateur linéaire.</p>
<p>Un hyperplan de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> est défini par</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T\mathbf x + b = 0\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf w\)</span> étant le vecteur normal à l’hyperplan. La fonction</p>
<div class="math notranslate nohighlight">
\[\label{eq:f} 
f({\mathbf x}) = \textrm{sign}( {\mathbf w^T\mathbf x} + b )
\]</div>
<p>permet, si elle sépare les données d’apprentissage, de les classifier correctement (<a class="reference internal" href="#hyp-ref"><span class="std std-numref">Fig. 13</span></a>).</p>
<figure class="align-default" id="hyp-ref">
<img alt="_images/hyperplan.png" src="_images/hyperplan.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Hyperplan séparateur et définition de <span class="math notranslate nohighlight">\(\mathbb w\)</span></span><a class="headerlink" href="#hyp-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<p>Un tel hyperplan, représenté par (<span class="math notranslate nohighlight">\(\mathbf w,b)\)</span> peut également être exprimé par <span class="math notranslate nohighlight">\((\lambda \mathbf w,\lambda b), \lambda\in\mathbb{R}\)</span>. Il est donc nécessaire de définir l’hyperplan canonique comme étant celui éloigné des données d’une distance au moins égale à 1. En fait, on impose qu’un exemple au moins de chaque classe soit à distance égale à 1. On considère alors le couple <span class="math notranslate nohighlight">\((\mathbf w,b)\)</span> tel que :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf w^T\mathbf x_i + b \ge +1 \ \ \textrm{si} \ \ y_i = +1 \\
\mathbf w^T\mathbf x_i + b \le -1 \ \ \textrm{si} \ \ y_i = -1
\end{split}\]</div>
<p>ou de manière plus compacte</p>
<div class="math notranslate nohighlight">
\[\forall i\quad y_i (\mathbf  w^T\mathbf x_i + b) \ge 1\]</div>
<p>les hyperplans <span class="math notranslate nohighlight">\(\mathbf w^T\mathbf x_i + b =\pm 1\)</span> sont appelés les hyperplans supports.</p>
<p>Une infinité d’hyperplans sépare deux nuages de points linéairement séparables (<a class="reference internal" href="#infhyp-ref"><span class="std std-numref">Fig. 14</span></a>)</p>
<figure class="align-default" id="infhyp-ref">
<img alt="_images/hyperplanmarge.png" src="_images/hyperplanmarge.png" />
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Hyperplans séparateurs</span><a class="headerlink" href="#infhyp-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<p>On cherche à avoir la marge la plus grande possible, et on suppose qu’au moins un point de donnée appartient aux hyperplans support. Il existe donc <span class="math notranslate nohighlight">\(\mathbf x_1,\mathbf x_2\)</span> tels que <span class="math notranslate nohighlight">\(\mathbf w^T\mathbf x_1 + b =1\)</span> et <span class="math notranslate nohighlight">\(\mathbf w^T\mathbf x_2 + b =-1\)</span>. On en déduit</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T(\mathbf x_1-\mathbf x_2) =2\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf w\)</span> étant orthogonal aux hyperplans, la marge est la projection orthogonale de <span class="math notranslate nohighlight">\(\mathbf x_1-\mathbf x_2\)</span> sur <span class="math notranslate nohighlight">\(\mathbf w\)</span>. Cette projection est définie par la matrice <span class="math notranslate nohighlight">\(P=\frac{\mathbf w\mathbf w^T}{\mathbf w^T\mathbf w}\)</span> et donc le vecteur projection de <span class="math notranslate nohighlight">\(\mathbf x_1-\mathbf x_2\)</span> sur la droite engendrée par <span class="math notranslate nohighlight">\(\mathbf w\)</span> est</p>
<div class="math notranslate nohighlight">
\[\frac{\mathbf w^T(x_1-\mathbf x_2)}{\mathbf w^T\mathbf w}\mathbf w = \frac{2}{\|\mathbf w\|}\]</div>
<p>L’équation précédente permet d’affirmer que maximiser la marge revient à minimiser <span class="math notranslate nohighlight">\(\|\mathbf w\|\)</span>, sous les contraintes de bonne classification (<a class="reference internal" href="#hyp2-ref"><span class="std std-numref">Fig. 15</span></a>).</p>
<figure class="align-default" id="hyp2-ref">
<img alt="_images/hyperplanmarge2.png" src="_images/hyperplanmarge2.png" />
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Maximisation de la marge</span><a class="headerlink" href="#hyp2-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
<section id="probleme-d-optimisation">
<h2>Problème d’optimisation<a class="headerlink" href="#probleme-d-optimisation" title="Lien vers cette rubrique">#</a></h2>
<p>Le problème s’écrit alors comme un problème de minimisation sous contraintes :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\min_{\mathbf w\in\mathbb{R}^d} \|\mathbf w \|^2\\
\textrm{sous }y_i(\mathbf  w^T\mathbf  x_i) \geq 1,\quad i\in[\![1,n]\!]\\
\end{split}\]</div>
<p>En introduisant les multiplicateurs de Lagrange, le problème dual s’écrit :</p>
<div class="math notranslate nohighlight">
\[
min  \ W(\boldsymbol\alpha) = -\displaystyle\sum_{i=1}^n{\alpha_i} +
\frac{1}{2} \displaystyle\sum_{i=1}^{n}\displaystyle \sum_{j=1}^ny_iy_j\alpha_i\alpha_j(\mathbf x_i ^T \mathbf x_j)  \]</div>
<p>sous</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sum_{i=1}^n y_i\alpha_i = 0 \]</div>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\; 0 \le \alpha_i \le C\]</div>
<p>où <span class="math notranslate nohighlight">\(\boldsymbol {\alpha}\)</span> est le vecteur des <span class="math notranslate nohighlight">\(n\)</span> multiplicateurs de Lagrange à déterminer, et <span class="math notranslate nohighlight">\(C\)</span> est une constante. En définissant la matrice <span class="math notranslate nohighlight">\((H)_{ij} = y_iy_j(\mathbf x_i ^T \mathbf x_j)\)</span> et <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> le vecteur de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> dont toutes les composantes sont égales à 1, le problème se réécrit comme un problème de programmation quadratique (QP) :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
min \label{eq:qp1}  W(\boldsymbol\alpha) = {-\boldsymbol\alpha}^T \mathbf{1} + \frac{1}{2}\boldsymbol\alpha^T H \boldsymbol\alpha
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp; \\
\textrm{sous } \label{eq:qp2}  \boldsymbol\alpha^T\boldsymbol y = 0
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp; \\
\label{eq:qp3}  {0} \le {\boldsymbol\alpha} \le C\mathbf{1}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp;
\end{split}\]</div>
<p>pour lequel de nombreuses méthodes de résolution ont été développées.</p>
<p>En dérivant l’équation précédente, il est possible de montrer que l’hyperplan optimal (canonique) peut être écrit comme</p>
<div class="math notranslate nohighlight">
\[\label{eq:w} \mathbf w = \displaystyle\sum_{i=1}^n \alpha_i y_i \mathbf x_i
\]</div>
<p>et <span class="math notranslate nohighlight">\(\mathbf w\)</span> est donc juste une combinaison linéaire des exemples d’apprentissage.</p>
<p>On peut également montrer que</p>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\quad \alpha_i(y_i(\mathbf w^T \mathbf x_i + b) - 1) = 0 
\]</div>
<p>ce qui exprime que lorsque <span class="math notranslate nohighlight">\(y_i(\mathbf w ^T \mathbf x_i + b) &gt; 1\)</span>, alors  <span class="math notranslate nohighlight">\(\alpha_i = 0\)</span> : seuls les points d’apprentissage les plus proches de l’hyperplan (tels que <span class="math notranslate nohighlight">\(\alpha_i &gt; 0\)</span>)  contribuent au calcul de ce dernier, et on les appelle les vecteurs de support.</p>
<p>En supposant avoir résolu le problème QP, et donc en disposant du <span class="math notranslate nohighlight">\(\boldsymbol {\alpha}\)</span> qui permet de calculer le vecteur <span class="math notranslate nohighlight">\(\mathbf w\)</span> optimal, il reste à déterminer le biais <span class="math notranslate nohighlight">\(b\)</span>. Pour cela, en prenant un exemple positif  <span class="math notranslate nohighlight">\(\mathbf x^+\)</span> et un exemple négatif  <span class="math notranslate nohighlight">\(\mathbf x^-\)</span> quelconques, pour lesquels</p>
<div class="math notranslate nohighlight">
\[\begin{split}(\mathbf w ^T \mathbf x^+ + b) = +1 \\
(\mathbf w ^T \mathbf x^- + b) = -1
\end{split}\]</div>
<p>on a</p>
<div class="math notranslate nohighlight">
\[b = - \frac{1}{2} ( \mathbf w ^T \mathbf x^+ + \mathbf w ^T \mathbf x^- )
\]</div>
<p>L’hyperplan ainsi défini a besoin de très peu de vecteurs de support (méthode éparse) (<a class="reference internal" href="#svmlin-ref"><span class="std std-numref">Fig. 16</span></a>).</p>
<div class="cell tag_margin tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=...</span>
<span class="n">svm_clf</span><span class="o">=</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="svmlin-ref">
<img alt="_images/svmLin.png" src="_images/svmLin.png" />
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Les vecteurs de support sont entourés.</span><a class="headerlink" href="#svmlin-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
<section id="donnees-non-lineairement-separables">
<h2>Données non linéairement séparables<a class="headerlink" href="#donnees-non-lineairement-separables" title="Lien vers cette rubrique">#</a></h2>
<p>Il reste à préciser le rôle de la contrainte <span class="math notranslate nohighlight">\({0} \le {\boldsymbol \alpha} \le C\mathbf{1}\)</span>.
Lorsque <span class="math notranslate nohighlight">\(C\rightarrow\infty\)</span>, l’hyperplan optimal est celui qui sépare totalement les données d’apprentissage (si tant est qu’il existe). Pour des valeurs de <span class="math notranslate nohighlight">\(C\)</span> « raisonnables », des erreurs de classification peuvent être acceptées par le classifieur (soft margin). Pour cela on introduit des variables d’écart <span class="math notranslate nohighlight">\(\xi_i\)</span> :</p>
<div class="math notranslate nohighlight">
\[\forall i\in[\![1,n]\!]\quad y_i(\mathbf w ^T \mathbf x_i + b) &gt; 1-\xi_i\]</div>
<p>Les vecteurs de support vérifient l’égalité, et les anciennes contraintes peuvent être violées de deux manières :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((\mathbf x_i,y_i)\)</span> est à distance inférieure à la marge, mais du bon côté de l’hyperplan</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf x_i,y_i)\)</span> est du mauvais côté de l’hyperplan</p></li>
</ul>
<p>L’objectif est alors de minimiser  la moyenne des erreurs de classification <span class="math notranslate nohighlight">\(\displaystyle\sum_{i=1}^n \mathbf{1}_{\xi_i&gt;0}\)</span>. Ce problème étant NP-complet (fonction non continue et dérivable), on lui préfère le problème suivant</p>
<div class="math notranslate nohighlight">
\[\begin{split}	Min \frac{1}{2}\mathbf w^T\mathbf w + C\displaystyle\sum_{i}^n \xi_i\\
	sous\;  y_i\left ( \mathbf w^T\mathbf x_i+b\right )= 1-\xi_i
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(C\)</span> représente alors un compromis entre la marge possible entre les exemples et le nombre d’erreurs admissibles.
Nous illustrons dans la suite deux situations influencées par <span class="math notranslate nohighlight">\(C\)</span> :</p>
<ul class="simple">
<li><p>La <a class="reference internal" href="#soft1-ref"><span class="std std-numref">Fig. 17</span></a> présente une première illustration du rôle de <span class="math notranslate nohighlight">\(C\)</span> : dans le cas de données linéairement séparables, un <span class="math notranslate nohighlight">\(C\)</span> faible autorisera des  vecteurs à rentrer dans la marge (vert). Plus <span class="math notranslate nohighlight">\(C\)</span> devient grand, plus le nombre de vecteurs support diminue, pour ne laisser aucun vecteur à distance inférieure à la marge de l’hyperplan optimal</p></li>
</ul>
<figure class="align-default" id="soft1-ref">
<img alt="_images/soft1.png" src="_images/soft1.png" />
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Données linéairement séparables</span><a class="headerlink" href="#soft1-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Video</span>
<span class="n">Video</span><span class="p">(</span><span class="s2">&quot;videos/influencec.mp4&quot;</span><span class="p">,</span><span class="n">embed</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_margin tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=...</span>
<span class="n">svm_clf</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1E10</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La <a class="reference internal" href="#soft2-ref"><span class="std std-numref">Fig. 18</span></a> présente un ensemble de données non linéairement séparables. La valeur de <span class="math notranslate nohighlight">\(C\)</span> contrôle le nombre d’erreurs de classification dans le résultat final.</p></li>
</ul>
<figure class="align-default" id="soft2-ref">
<img alt="_images/soft2.png" src="_images/soft2.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Données non linéairement séparables</span><a class="headerlink" href="#soft2-ref" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
<section id="cas-multiclasses">
<h2>Cas multiclasses<a class="headerlink" href="#cas-multiclasses" title="Lien vers cette rubrique">#</a></h2>
<p>Deux stratégies sont possibles dans le cas multiclasse :</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
Un contre tous</label><div class="sd-tab-content docutils">
<p>Transformer le problème à <span class="math notranslate nohighlight">\(k\)</span> classes en <span class="math notranslate nohighlight">\(k\)</span> classifieurs binaires, la classe de l’exemple est donnée par le classifieur qui répond le mieux
<img alt="" src="_images/ova1.png" /></p>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
Un contre un</label><div class="sd-tab-content docutils">
<p>Transformer le problème en <span class="math notranslate nohighlight">\(\frac{k(k-1)}{2}\)</span> classifieurs binaires, chaque classe étant comparée aux autres. La classe de l’exemple est donnée par le vote majoritaire ou par un graphe acyclique de décision
<img alt="" src="_images/ova2.png" /></p>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="svm-non-lineaire">
<h1>SVM non linéaire<a class="headerlink" href="#svm-non-lineaire" title="Lien vers cette rubrique">#</a></h1>
<p>Pour utiliser les SVM dans un contexte non linéaire, on profite de l”<a class="reference internal" href="kernelTrick.html"><span class="std std-doc">astuce du noyau</span></a> puisque le modèle s’écrit avec un produit scalaire canonique.</p>
<aside class="margin sidebar">
<p class="sidebar-title">Exemple de regression</p>
<p><img alt="" src="_images/ridgeregression.png" /></p>
</aside>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="utilisation-en-regression">
<h1>Utilisation en régression<a class="headerlink" href="#utilisation-en-regression" title="Lien vers cette rubrique">#</a></h1>
<p>Il est également possible, en changeant les fonctions de perte,  d’utiliser les SVM  en régression non paramétrique (SVR : Support Vector Regression)
, i.e. approcher une fonction de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> dans <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span> par les mêmes mécanismes d’optimisation.</p>
<p>Pour illustrer les SVR, on génère des données aléatoires 2D à tendance linéaire et on utilise LinearSVR pour effectuer une régression linéaire.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$y$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="s2">&quot;bo&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Un SVR linéaire est principalement défini par un paramètre <span class="math notranslate nohighlight">\(\epsilon\)</span>, qui spécifie la largeur du tube dans lequel aucune pénalité n’est associée.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>
<span class="n">svm_reg1</span> <span class="o">=</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_reg2</span> <span class="o">=</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_reg1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">svm_reg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">off_margin</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">off_margin</span><span class="p">)</span>

<span class="n">svm_reg1</span><span class="o">.</span><span class="n">support_</span> <span class="o">=</span> <span class="n">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">svm_reg2</span><span class="o">.</span><span class="n">support_</span> <span class="o">=</span> <span class="n">find_support_vectors</span><span class="p">(</span><span class="n">svm_reg2</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">eps_x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">eps_y_pred</span> <span class="o">=</span> <span class="n">svm_reg1</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">eps_x1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>On affiche alors les régresseurs linéaires</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">x1s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x1s</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="s2">&quot;c-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\hat</span><span class="si">{y}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1s</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">svm_reg</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">svm_reg</span><span class="o">.</span><span class="n">support_</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">svm_reg</span><span class="o">.</span><span class="n">support_</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;#FFAAAA&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$y$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg1</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\epsilon = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svm_reg1</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">eps_x1</span><span class="p">,</span> <span class="n">eps_y_pred</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">eps_x1</span><span class="p">,</span> <span class="n">eps_y_pred</span> <span class="o">-</span> <span class="n">svm_reg1</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">arrowprops</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;arrowstyle&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;-&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;linewidth&#39;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">}</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.91</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\epsilon$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plot_svm_regression</span><span class="p">(</span><span class="n">svm_reg2</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\epsilon = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svm_reg2</span><span class="o">.</span><span class="n">epsilon</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Video</span>
<span class="n">Video</span><span class="p">(</span><span class="s2">&quot;videos/svr_regression_lin.mp4&quot;</span><span class="p">,</span><span class="n">embed</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="docutils container" id="id1">
<div role="list" class="citation-list">
<div class="citation" id="id61" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cov65<span class="fn-bracket">]</span></span>
<p>Thomas M. Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. <em>Electronic Computers, IEEE Transactions on</em>, EC-14(3):326–334, 1965. URL: <a class="reference external" href="http://hebb.mit.edu/courses/9.641/2002/readings/Cover65.pdf">http://hebb.mit.edu/courses/9.641/2002/readings/Cover65.pdf</a>.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>VC71<span class="fn-bracket">]</span></span>
<p>V. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. <em>Theory of Probability and its Applications</em>, 16(2):264–280, 1971.</p>
</div>
<div class="citation" id="id50" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Vap91<span class="fn-bracket">]</span></span>
<p>Vladimir Vapnik. Principles of risk minimization for learning theory. In <em>NIPS</em>, 831–838. Morgan Kaufmann, 1991.</p>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="docKernels.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">Ressources</p>
      </div>
    </a>
    <a class="right-next"
       href="kernelTrick.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Astuce du noyau</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenu
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">SVM linéaire</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperplan-separateur">Hyperplan séparateur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probleme-d-optimisation">Problème d’optimisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#donnees-non-lineairement-separables">Données non linéairement séparables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cas-multiclasses">Cas multiclasses</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-non-lineaire">SVM non linéaire</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#utilisation-en-regression">Utilisation en régression</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Par Vincent BARRA
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>