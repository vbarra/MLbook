Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 1093, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/local/lib/python3.9/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/usr/local/lib/python3.9/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/local/Cellar/python@3.9/3.9.17/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 559, in async_execute
    await self.async_execute_cell(
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 854, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 756, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from scipy import linalg
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib import colors

import warnings
warnings.filterwarnings('ignore')

# Affichage 
def Ellipse(splot, mean, cov, color):
    v, w = linalg.eigh(cov)
    u = w[0] / linalg.norm(w[0])
    angle = np.arctan(u[1] / u[0])
    angle = 180 * angle / np.pi  
    ell = mpl.patches.Ellipse(mean, 2 * v[0] ** 0.5, 2 * v[1] ** 0.5,
                              180 + angle, facecolor=color, edgecolor='yellow',
                              linewidth=2, zorder=2)
    ell.set_clip_box(splot.bbox)
    ell.set_alpha(0.5)
    splot.add_artist(ell)
    splot.set_xticks(())
    splot.set_yticks(())
    

def plot_data(lda, X, y, y_pred, title,i):
    splot = plt.subplot(1, 2, i)

    plt.title(title)

    tp = (y == y_pred) 
    tp0, tp1 = tp[y == 0], tp[y == 1]
    X0, X1 = X[y == 0], X[y == 1]
    X0_tp, X0_fp = X0[tp0], X0[~tp0]
    X1_tp, X1_fp = X1[tp1], X1[~tp1]

    alpha = 0.5

    plt.plot(X0_tp[:, 0], X0_tp[:, 1], 'o', alpha=alpha,color='red')
    plt.plot(X0_fp[:, 0], X0_fp[:, 1], '*', alpha=alpha,color='#990000')  

    plt.plot(X1_tp[:, 0], X1_tp[:, 1], 'o', alpha=alpha,color='blue')
    plt.plot(X1_fp[:, 0], X1_fp[:, 1], '*', alpha=alpha,color='#000099')  

    nx, ny = 200, 100
    x_min, x_max = plt.xlim()
    y_min, y_max = plt.ylim()
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),
                         np.linspace(y_min, y_max, ny))
    Z = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])
    Z = Z[:, 1].reshape(xx.shape)
    plt.pcolormesh(xx, yy, Z, cmap='red_blue_classes',norm=colors.Normalize(0., 1.))
    plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='k')

    plt.plot(lda.means_[0][0], lda.means_[0][1],
             'o', color='black', markersize=10)
    plt.plot(lda.means_[1][0], lda.means_[1][1],
             'o', color='black', markersize=10)
    plt.gca().set_aspect("equal")
    return splot

def plot_cov(method, splot):
    if method==lda:
        Ellipse(splot, method.means_[0], method.covariance_, 'red')
        Ellipse(splot, method.means_[1], method.covariance_, 'blue')
    else:
        Ellipse(splot, method.means_[0], method.covariance_[0], 'red')
        Ellipse(splot, method.means_[1], method.covariance_[1], 'blue')



from sklearn.datasets import make_blobs
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

nb_exemples = 20  
nb_test = 200  
n_averages = 50  
n_max = 75  

def blobs(n_samples, n_features):
    X, y = make_blobs(n_samples=n_samples, n_features=1, centers=[[-2], [2]])
    # ajout de descripteurs non discriminants
    if n_features > 1:
        X = np.hstack([X, np.random.randn(n_samples, n_features - 1)])
    return X, y

acc_lda, acc_ldas = [], []
nb_descripteurs = range(1, n_max, 5)
for n_features in nb_descripteurs:
    score_lda, score_ldas = 0, 0
    for _ in range(n_averages):
        X, y = blobs(nb_exemples, n_features)

        lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto').fit(X, y)
        ldas = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=None).fit(X, y)

        X, y = blobs(nb_test, n_features)
        score_lda += lda.score(X, y)
        score_ldas += ldas.score(X, y)

    acc_lda.append(score_lda / n_averages)
    acc_ldas.append(score_ldas / n_averages)

ratio = np.array(nb_descripteurs) / nb_exemples

plt.plot(ratio, acc_lda,
         label="LDA + shrinkage")
plt.plot(ratio, acc_ldas,
         label="LDA seul")

plt.xlabel('nb_descripteurs / nb_exemples')
plt.ylabel('Pr√©cision de la classification')

plt.legend(loc='best')
plt.tight_layout()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyboardInterrupt[0m                         Traceback (most recent call last)
Input [0;32mIn [1][0m, in [0;36m<module>[0;34m[0m
[1;32m     91[0m [38;5;28;01mfor[39;00m _ [38;5;129;01min[39;00m [38;5;28mrange[39m(n_averages):
[1;32m     92[0m     X, y [38;5;241m=[39m blobs(nb_exemples, n_features)
[0;32m---> 94[0m     lda [38;5;241m=[39m [43mLinearDiscriminantAnalysis[49m[43m([49m[43msolver[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mlsqr[39;49m[38;5;124;43m'[39;49m[43m,[49m[43m [49m[43mshrinkage[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mauto[39;49m[38;5;124;43m'[39;49m[43m)[49m[38;5;241;43m.[39;49m[43mfit[49m[43m([49m[43mX[49m[43m,[49m[43m [49m[43my[49m[43m)[49m
[1;32m     95[0m     ldas [38;5;241m=[39m LinearDiscriminantAnalysis(solver[38;5;241m=[39m[38;5;124m'[39m[38;5;124mlsqr[39m[38;5;124m'[39m, shrinkage[38;5;241m=[39m[38;5;28;01mNone[39;00m)[38;5;241m.[39mfit(X, y)
[1;32m     97[0m     X, y [38;5;241m=[39m blobs(nb_test, n_features)

File [0;32m/usr/local/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:624[0m, in [0;36mLinearDiscriminantAnalysis.fit[0;34m(self, X, y)[0m
[1;32m    622[0m     [38;5;28mself[39m[38;5;241m.[39m_solve_svd(X, y)
[1;32m    623[0m [38;5;28;01melif[39;00m [38;5;28mself[39m[38;5;241m.[39msolver [38;5;241m==[39m [38;5;124m"[39m[38;5;124mlsqr[39m[38;5;124m"[39m:
[0;32m--> 624[0m     [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_solve_lstsq[49m[43m([49m
[1;32m    625[0m [43m        [49m[43mX[49m[43m,[49m
[1;32m    626[0m [43m        [49m[43my[49m[43m,[49m
[1;32m    627[0m [43m        [49m[43mshrinkage[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mshrinkage[49m[43m,[49m
[1;32m    628[0m [43m        [49m[43mcovariance_estimator[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mcovariance_estimator[49m[43m,[49m
[1;32m    629[0m [43m    [49m[43m)[49m
[1;32m    630[0m [38;5;28;01melif[39;00m [38;5;28mself[39m[38;5;241m.[39msolver [38;5;241m==[39m [38;5;124m"[39m[38;5;124meigen[39m[38;5;124m"[39m:
[1;32m    631[0m     [38;5;28mself[39m[38;5;241m.[39m_solve_eigen(
[1;32m    632[0m         X,
[1;32m    633[0m         y,
[1;32m    634[0m         shrinkage[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mshrinkage,
[1;32m    635[0m         covariance_estimator[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mcovariance_estimator,
[1;32m    636[0m     )

File [0;32m/usr/local/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:401[0m, in [0;36mLinearDiscriminantAnalysis._solve_lstsq[0;34m(self, X, y, shrinkage, covariance_estimator)[0m
[1;32m    354[0m [38;5;124;03m"""Least squares solver.[39;00m
[1;32m    355[0m 
[1;32m    356[0m [38;5;124;03mThe least squares solver computes a straightforward solution of the[39;00m
[0;32m   (...)[0m
[1;32m    398[0m [38;5;124;03m   0-471-05669-3.[39;00m
[1;32m    399[0m [38;5;124;03m"""[39;00m
[1;32m    400[0m [38;5;28mself[39m[38;5;241m.[39mmeans_ [38;5;241m=[39m _class_means(X, y)
[0;32m--> 401[0m [38;5;28mself[39m[38;5;241m.[39mcovariance_ [38;5;241m=[39m [43m_class_cov[49m[43m([49m
[1;32m    402[0m [43m    [49m[43mX[49m[43m,[49m[43m [49m[43my[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mpriors_[49m[43m,[49m[43m [49m[43mshrinkage[49m[43m,[49m[43m [49m[43mcovariance_estimator[49m
[1;32m    403[0m [43m[49m[43m)[49m
[1;32m    404[0m [38;5;28mself[39m[38;5;241m.[39mcoef_ [38;5;241m=[39m linalg[38;5;241m.[39mlstsq([38;5;28mself[39m[38;5;241m.[39mcovariance_, [38;5;28mself[39m[38;5;241m.[39mmeans_[38;5;241m.[39mT)[[38;5;241m0[39m][38;5;241m.[39mT
[1;32m    405[0m [38;5;28mself[39m[38;5;241m.[39mintercept_ [38;5;241m=[39m [38;5;241m-[39m[38;5;241m0.5[39m [38;5;241m*[39m np[38;5;241m.[39mdiag(np[38;5;241m.[39mdot([38;5;28mself[39m[38;5;241m.[39mmeans_, [38;5;28mself[39m[38;5;241m.[39mcoef_[38;5;241m.[39mT)) [38;5;241m+[39m np[38;5;241m.[39mlog(
[1;32m    406[0m     [38;5;28mself[39m[38;5;241m.[39mpriors_
[1;32m    407[0m )

File [0;32m/usr/local/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:169[0m, in [0;36m_class_cov[0;34m(X, y, priors, shrinkage, covariance_estimator)[0m
[1;32m    167[0m [38;5;28;01mfor[39;00m idx, group [38;5;129;01min[39;00m [38;5;28menumerate[39m(classes):
[1;32m    168[0m     Xg [38;5;241m=[39m X[y [38;5;241m==[39m group, :]
[0;32m--> 169[0m     cov [38;5;241m+[39m[38;5;241m=[39m priors[idx] [38;5;241m*[39m np[38;5;241m.[39matleast_2d([43m_cov[49m[43m([49m[43mXg[49m[43m,[49m[43m [49m[43mshrinkage[49m[43m,[49m[43m [49m[43mcovariance_estimator[49m[43m)[49m)
[1;32m    170[0m [38;5;28;01mreturn[39;00m cov

File [0;32m/usr/local/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:73[0m, in [0;36m_cov[0;34m(X, shrinkage, covariance_estimator)[0m
[1;32m     71[0m     s [38;5;241m=[39m ledoit_wolf(X)[[38;5;241m0[39m]
[1;32m     72[0m     [38;5;66;03m# rescale[39;00m
[0;32m---> 73[0m     s [38;5;241m=[39m [43msc[49m[38;5;241;43m.[39;49m[43mscale_[49m[43m[[49m[43m:[49m[43m,[49m[43m [49m[43mnp[49m[38;5;241;43m.[39;49m[43mnewaxis[49m[43m][49m[43m [49m[38;5;241;43m*[39;49m[43m [49m[43ms[49m [38;5;241m*[39m sc[38;5;241m.[39mscale_[np[38;5;241m.[39mnewaxis, :]
[1;32m     74[0m [38;5;28;01melif[39;00m shrinkage [38;5;241m==[39m [38;5;124m"[39m[38;5;124mempirical[39m[38;5;124m"[39m:
[1;32m     75[0m     s [38;5;241m=[39m empirical_covariance(X)

[0;31mKeyboardInterrupt[0m: 
KeyboardInterrupt: 

